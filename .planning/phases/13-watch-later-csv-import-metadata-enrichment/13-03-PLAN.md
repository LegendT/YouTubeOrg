---
phase: 13-watch-later-csv-import-metadata-enrichment
plan: 03
type: execute
wave: 3
depends_on: ["13-01", "13-02"]
files_modified:
  - src/app/actions/import.ts
autonomous: true

must_haves:
  truths:
    - "playlistVideos entries are created linking each video to the Watch Later playlist"
    - "CSV row order is preserved as the position field (first row = position 0)"
    - "CSV timestamps are used as the addedAt field"
    - "Re-import does not create duplicate playlistVideos entries"
    - "Counts of created and skipped relationships are returned"
  artifacts:
    - path: "src/app/actions/import.ts"
      provides: "createPlaylistRelationships server action"
      exports: ["parseAndInitialiseImport", "importMetadataBatch", "createPlaylistRelationships"]
  key_links:
    - from: "src/app/actions/import.ts"
      to: "src/lib/db/schema.ts"
      via: "Drizzle insert into playlistVideos with application-level dedup"
      pattern: "insert\\(playlistVideos\\)"
    - from: "src/app/actions/import.ts"
      to: "src/lib/db/schema.ts"
      via: "Query existing playlistVideos for dedup check"
      pattern: "select.*from\\(playlistVideos\\).*where.*playlistId"
---

<objective>
Create the playlist-video relationship records that link imported videos to the Watch Later playlist, with application-level deduplication for re-import safety.

Purpose: After CSV parsing (13-01) and metadata enrichment (13-02), videos exist in the `videos` table and the Watch Later playlist exists in `playlists`. This plan creates the `playlistVideos` junction records that complete the data model. The critical challenge is that `playlistVideos` has NO unique constraint on `(playlist_id, video_id)` — only a serial primary key — so re-import MUST use application-level deduplication to prevent duplicate rows.

Output: A new `createPlaylistRelationships` export added to `src/app/actions/import.ts`.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/phases/13-watch-later-csv-import-metadata-enrichment/13-RESEARCH.md

Key codebase references:
@src/lib/db/schema.ts — playlistVideos table (lines 36-42): serial PK, playlistId FK, videoId FK, position, addedAt. NO unique constraint on (playlistId, videoId).
@src/lib/youtube/videos.ts — lines 149-157: existing onConflictDoNothing usage (operates against serial PK, not composite — confirmed in research)

CRITICAL from RESEARCH (Pitfall 1): The playlistVideos table has NO unique constraint on (playlist_id, video_id). The existing onConflictDoNothing in videos.ts operates against the serial PK, not a composite key. Re-import MUST use application-level deduplication: query existing relationships, build a Set, skip duplicates.

CRITICAL from RESEARCH (Open Question 3): Batch insert in chunks of 500 after filtering to new-only rows. This balances performance with memory usage.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Playlist-video relationship creation with application-level deduplication</name>
  <files>
    src/app/actions/import.ts
  </files>
  <action>
    Add to the existing `src/app/actions/import.ts` file (which already has parseAndInitialiseImport and importMetadataBatch from Plans 13-01 and 13-02).

    Add imports if not already present: `playlistVideos` from `@/lib/db/schema`, `eq` from `drizzle-orm`.

    Import `ParsedCSVRow` from `@/lib/import/csv-parser` if not already imported.

    Export async function `createPlaylistRelationships(playlistDbId: number, rows: ParsedCSVRow[])` returning:
    ```typescript
    Promise<{
      success: boolean;
      created: number;
      skipped: number;
      error?: string;
    }>
    ```

    Implementation:

    1. Auth check (same pattern as other actions in this file).

    2. Get all video DB IDs for the YouTube IDs in the CSV:
       ```typescript
       const youtubeIds = rows.map(r => r.videoId);
       // Query in batches of 500 to avoid exceeding SQL parameter limits
       const videoRecords: { id: number; youtubeId: string }[] = [];
       for (let i = 0; i < youtubeIds.length; i += 500) {
         const chunk = youtubeIds.slice(i, i + 500);
         const records = await db
           .select({ id: videos.id, youtubeId: videos.youtubeId })
           .from(videos)
           .where(inArray(videos.youtubeId, chunk));
         videoRecords.push(...records);
       }
       const youtubeToDbId = new Map(videoRecords.map(v => [v.youtubeId, v.id]));
       ```

    3. APPLICATION-LEVEL DEDUPLICATION (critical — no unique constraint exists):
       ```typescript
       const existingRelations = await db
         .select({ videoId: playlistVideos.videoId })
         .from(playlistVideos)
         .where(eq(playlistVideos.playlistId, playlistDbId));
       const existingVideoIds = new Set(existingRelations.map(r => r.videoId));
       ```

    4. Build the insert list, filtering out duplicates:
       ```typescript
       const toInsert: { playlistId: number; videoId: number; position: number; addedAt: Date }[] = [];
       let skipped = 0;

       for (let i = 0; i < rows.length; i++) {
         const row = rows[i];
         const dbId = youtubeToDbId.get(row.videoId);
         if (!dbId) continue; // Video record not found (should not happen if 13-02 completed)

         if (existingVideoIds.has(dbId)) {
           skipped++;
           continue;
         }

         toInsert.push({
           playlistId: playlistDbId,
           videoId: dbId,
           position: i, // CSV order preserved: first row = position 0
           addedAt: new Date(row.addedAt),
         });
       }
       ```

    5. Batch insert in chunks of 500:
       ```typescript
       for (let i = 0; i < toInsert.length; i += 500) {
         const chunk = toInsert.slice(i, i + 500);
         await db.insert(playlistVideos).values(chunk);
       }
       ```

    6. Return `{ success: true, created: toInsert.length, skipped }`.

    7. Wrap everything in try/catch. On error, return `{ success: false, created: 0, skipped: 0, error: message }`.

    Note: This action is called ONCE after all metadata batches complete (not per-batch). The entire relationship creation runs in a single invocation because it is purely DB work (no API calls) and should complete in seconds even for 3,932 rows.
  </action>
  <verify>
    `npx tsc --noEmit` passes.
    createPlaylistRelationships is exported from src/app/actions/import.ts.
    The function: (a) queries existing relationships before inserting, (b) skips videos that already have relationships (dedup), (c) preserves CSV ordering as position, (d) uses CSV timestamps as addedAt, (e) batch inserts in chunks of 500.
  </verify>
  <done>
    createPlaylistRelationships creates junction records linking videos to the Watch Later playlist. It uses application-level deduplication (queries existing relationships, builds a Set, skips duplicates) because the playlistVideos table has no unique constraint. CSV row order is preserved as position (0-indexed). Batch inserts in chunks of 500 for performance. Returns {created, skipped} counts.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` — no type errors
2. Application-level dedup: queries existingRelations BEFORE inserting
3. Position field uses CSV row index (0-based)
4. addedAt field uses CSV timestamp (parsed as Date)
5. Batch inserts in chunks of 500
6. Re-import creates NO duplicate rows (skipped count reflects existing)
</verification>

<success_criteria>
- playlistVideos entries correctly link videos to Watch Later playlist
- CSV ordering preserved as position field
- CSV timestamps used as addedAt field
- Re-import is fully idempotent — no duplicate relationships created
- Returns accurate created/skipped counts for the UI summary
</success_criteria>

<output>
After completion, create `.planning/phases/13-watch-later-csv-import-metadata-enrichment/13-03-SUMMARY.md`
</output>
